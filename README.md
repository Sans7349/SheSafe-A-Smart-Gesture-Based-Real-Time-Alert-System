In my project, I have been reading about SheSafe, an AI-based application to improve the safety of women, which identifies hand gestures in real time and accurately recognizes them. It addresses traditional pain points such as low-light detection, lack of labeled data, and the necessity to achieve high accuracy with the lowest number of false alarms. In contrast to voice or mobile SOS applications that may crash during real-life conditions, SheSafe provides a reliable non-verbal option. The conventional gesture recognition devices tend to fall behind due to delays and misidentification. In the case of SheSafe, the team combines OpenCV to handle the video pipeline, MediaPipe to track the hands, and a deep neural network to make the classifications remain fast. I have witnessed the ability of this stack to fill the gap between fast glance detection and the strength of a solid model. To measure its effectiveness, we used standard metrics such as precision, recall, F1 score, ReLU output layers, and total accuracy. The performance was good and the feedback indicated that the system is not only competitive but also faster and more responsive than many existing solutions. I have been writing down these results in my semester report, giving reference to the evaluation figures to support the arguments. I have also spent much time on the ethical front: data privacy, ownership of gesture data, and how issues of surveillance creep in. We have ensured to incorporate privacy-by-design principles and remain as least intrusive as possible in the system, which I intend to emphasize in the ethics section of my paper. All in all, SheSafe shows that AI-based gesture recognition as an emergency communication device can be considered a valid solution.
